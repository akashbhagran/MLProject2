name: your-workflow-name
on: [push]
jobs:
  run:
    services:
      mlflow:
        image: ghcr.io/mlflow/mlflow:v2.0.1
        ports:
          - 5000:5000
        options: >-
          --name mlflow
          --entrypoint ""
          mlflow mlflow server
          --backend-store-uri /mlflow
          --default-artifact-root /mlflow/artifacts
          --host 0.0.0.0
          --port 5000
    runs-on: ubuntu-latest
    # optionally use a convenient Ubuntu LTS + DVC + CML image
    # container: ghcr.io/iterative/cml:0-dvc2-base1
    steps:
      - uses: actions/checkout@v3
      # may need to setup NodeJS & Python3 on e.g. self-hosted
      # - uses: actions/setup-node@v3
      #   with:
      #     node-version: '16'
      - run: |
          pwd
          ls -la
          cd train
          ls -la
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - uses: iterative/setup-cml@v1
      - name: Train model
        run: |
          # Your ML workflow goes here
          pip install -r .github/workflows/requirements.txt
          cd train
          python train.py
      - name: Write CML report
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Post reports as comments in GitHub PRs
          cat results.txt >> report.md
          cml comment create report.md
      